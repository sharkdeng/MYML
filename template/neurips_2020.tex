\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
% \usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
     \usepackage[final]{neurips_2020}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{natbib}  %reference
\usepackage{listings} % code
% begin code style 

\usepackage{color} 
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
% end code style





\title{Clustering to Classify Histological Images}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Limin Deng\\
  College of Engineering \& Computer Science \\
  the Australian National University\\
  Canberra ACT 2600 Australia\\
  \texttt{u6849956@anu.edu.au} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}

\maketitle

\begin{abstract}

This paper reviews several strategies applied in the stock market and After comparing their performance, we proposed a novel method, called adversarial agents, which use the idea of GAN to get better prediction result. 

Stock market can be regarded as the combination of makers' actions and retail investors' actions. The one party's intention is to win the other party's investment and increase self earnings as much as possible. In this paper, we innovatively propose adversarial agents 

Long and Short Term Memory (LSTM) has achieved great success in predicting time-series data and Efficientnet in image classification. In this paper, we explored several types of LSTM and compared their performance in predicting Chinese Stock prices. We also explored the power of combination of LSTM and Efficientnet. It proves that the combination achieved very high accuracy.  
The code is available at https://github.com/sharkdeng/stock. \par
\textbf{Keywords:} LSTM, stock
\end{abstract}

\section{Introduction}

NeurIPS requires electronic submissions.  The electronic submission site is
\begin{center}
  \url{https://cmt3.research.microsoft.com/NeurIPS2020/}
\end{center}

Please read the instructions below carefully and follow them faithfully.





\section{Related Work}

\subsection{K-means++}


Affinity Propagation
Agglomerative Clustering
BIRCH
DBSCAN
K-Means
Mini-Batch K-Means
Mean Shift
OPTICS
Spectral Clustering
Mixture of Gaussians





\subsection{Preprocessing}

\subsection{Training}

\subsection{PostProcessing}


\section{Result}


\section{Conclusion}


\section{Acknowledgment}



 \bibliographystyle{agsm}
 \bibliography{ref.bib}

\end{document}
